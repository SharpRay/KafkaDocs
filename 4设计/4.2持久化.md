# 持久化

## 不要惧怕文件系统！

Kafka重度依赖文件系统，用于存储和缓存消息。一个普遍的看法是"磁盘很慢"，这使得人们怀疑一个持久化的框架是否能提供良好的性能。事实上，磁盘比人们期望的慢，也会比人们的期望的快，这取决于如何使用磁盘；一个合理设计的磁盘结构能够提供和网络一样快的性能。

关于磁盘性能关键的事实是，最近10年间，制约磁盘吞吐性能的因素已经不再是寻址的延迟。在一个[JBOD](http://en.wikipedia.org/wiki/Non-RAID_drive_architectures)（just a bunch of disks，这个架构中有很多块磁盘，它们可以作为多个独立的磁盘或者联合的一块不带有RAID功能的逻辑磁盘访问）配置的6块7200转SATA RAID-5磁盘阵列中，线性写入的性能大概是600MB/秒，但是粹机写的性能却只有100k/秒-6000倍的性能差距。所有应用模式的这些线性读写是最可预测的，并且被操作系统做了深入优化。一个现代操作系统提供预读（read-ahead）和延迟写（write-behind）技术，能够预先获取数据以及将多个小的逻辑写入打包成一个大的物理写入。对这方面的深入讨论可以在[ACM Queue article](http://queue.acm.org/detail.cfm?id=1563874)中找到；实际上他们发现[顺序磁盘访问在有些场景中比随机内存访问要快!](http://deliveryimages.acm.org/10.1145/1570000/1563874/jacobs3.jpg)

为了补偿这种性能差异，现代操作系统在使用主存作为磁盘缓存这方便变得越来越激进。一个现代操作系统几乎将所有可用内存用作磁盘缓存，这在内存回收时会有小小的性能惩罚。所有磁盘读写都会进入到这个统一的缓存中。这个特性不能在没有使用[direct I/O](https://www.ibm.com/developerworks/cn/linux/l-cn-directio/)的情况下简单地关闭，因此尽管一个进程维护一个进程内的数据缓存，这份数据还是会复制到OS的pagecache中，有效地把任何数据都存储了两份。

还有就是我们在JVM上构建应用，任何使用java内存的人都知道两件事：

1. 对象的内存开销非常高，一般是存储数据的两倍（或更多）。
2. Java的垃圾收集机制变得日益繁琐并且随着堆内数据增加变得很慢。

基于这些因素的结果是，使用文件系统并依赖pagecache的方案比维护一个缓存或其他架构要好-至少我们通过自动访问所有剩余内存使得可用缓存翻倍（进程内不缓存数据），并且通过存储压缩字节数据结构比存储单个对象又使可用内存翻倍。这样做会导致在一个32GB的机器上使用28-30GB的缓存，不会带来GC性能惩罚。更进一步说，这个缓存在服务重启后仍然缓存的是热数据，而进程内的缓存则需要在内存中重建（10GB数据可能需要10分钟），否则进程就要带着一个完全的冷缓存启动（这意味着非常差的初始性能）。同时，使用页面缓存能极大简化代码，因为所有的维护缓存和文件系统之间一致性的工作都交给了OS，使得比起进程内的一次性尝试更高效，正确性也更高。如果你对磁盘的使用倾向于线性度祛，那么预读机制会高效地在每次磁盘读取时填充缓存。

以上这些提供了一个非常简单的设计：比起在内存中维护数据并在用光内存时惊恐地将数据flush到文件系统，我们选择颠倒这个过程。所有数据立即被写入文件系统上的一个持久化的日志，没有不必要的flush磁盘操作。事实上，这只是意味着数据被发送到内核的pagecache中。

这种集中于pagecache的设计模式在一篇关于Varnish cache设计的[文章](http://varnish.projects.linpro.no/wiki/ArchitectNotes)中有描述。

## 对常数时间的需求

在消息系统中使用的持久化的数据结构通过是每个consumer一个队列，每个队列使用一棵相关的B树或其他通用随机访问数据结构去维护消息的元数据。B树是可用的最灵活的数据结构，并且能支持消息系统中的广泛的事务和非事务的语义。B树的开销相对较高，尽管B树操作的时间复杂度是O(logN)。