# Producer配置

下面列出了Java producer的配置：

| Name | Decription | Type | Default | Valid Values | Importance |
| --- | --- | --- | --- | --- | --- |
| bootstrap.servers | 一个host\/port对列表，用于创建到Kafka cluster的初始连接。客户端会使用所有的Kafka servers，而不只是这个选项中列出的用于初始化立连接的servers。这个列表只是用于发现完整servers集合的初始化主机集合。这个列表的形式为host1:port1,host2:port2,...。由于这些server只是用于初始化连接发现完完整集群（可能会动态变化）的，因此这个列表没必要包含所有的server（你可能想要指定多于一个server，以防server宕机） | list |  |  | high |
| key.serializer | key的实现了Serializer接口的Serializer类 | class |  |  | high |
| value.serializer | value的实现了Serializer接口的Serializer类 | class |  |  | high |
| acks | producer认为请求完成之前需要leader收到（followers）的确认数。这个选项指定了producer发送消息给server的持久化级别。有下面的配置：_ acks=0 如果acks设置为0，则producer不会等待server的任何确认。消息会立即加入到socket buffer并认为已送达。这种情况没有任何servers已收到消息的保证，并且retries配置不会有任何作用（因为客户端不会知道有任何失败的情况发生）。每条消息返回的offset都是-1。 _ acks=1 这意味着leader会将消息写入它本地log中，但是不会等待从其他followers来的完整绝人就向客户端返回响应。这种情况下，leader在确认之后在followrs复制数据之前马上失效则消息会丢失。 \_ acks=all 这意味着leader会等待完成的ISR确认收到消息之后才返回客户端响应。这保证只要有一个in-sync的副本存活就不会丢数据。这是最强的可用性保证。 | string | 1 | \[all,-1,0,1\] | high |
|buffer.memory|producer能够用于缓冲等待发送到server的消息的内存字节数。如果消息发送的速度大于它们能够被传递给server的速度则会发生阻塞，阻塞max.block.ms后会抛异常。这个设置应该等于producer总的可用内存，但是不是一个硬边界限制，因为不是所有producer的内存都是用于数据缓冲的。有些附加的内存会用于压缩（如果启用了压缩）以及维护进行中的请求。|long|33554432|[0,...]|high|
|compression.type|用于producer产生的数据的压缩类型。默认是none（不压缩）。可用的值有none,gzip,snappy和lz4。压缩是用于完整的数据batch，因此batch的效率也会影响到压缩的比率（更多数据的batching意味着更好的压缩比）。|string|none||high|
|retries|设置一个大于0的值会导致客户端重新发送由于一个潜在短暂的错误而发送失败的消息。需要注意的是，这个retry和客户端收到一个错误重新发送消息没有区别。开启重试但是没有设置max.in.flight.request.per.connection为1的话，会改变消息的顺序，因为如果两个batch发送给一个分区，第一个batch失败重试但是第二个batch成功，则第二个batch可能会先到达分区。|int|0|[00,...,2147483647]|high|
|ssl.key.password|||||high|
|ssl.keystore.location|||||high|
|ssl.keystore.password|||||high|
|ssl.truststore.location|||||high|
|ssl.truststore.password|||||high|
|batch.size|producer会将发送到同一个分区的消息批量打包，以减少请求次数。这有助于提高客户端和服务端的性能。这个配置指定了默认的batch字节数。发送给brokers的多个请求包含多个batch，每个请求包含发送给一个分区的数据。小的batch会降低吞吐（batch size为0会禁用batching机制）。一个太大的batch size可能会浪费内从，因为我们总是申请指定的batch size的buffer去等待更多的消息。|int|16384|[0,...]|medium|
|client.id|发送请求时传递给server的id字符串。目的是通过允许一个逻辑应用程序名称可以包含在server端的请求日志中，不只是通过ip/port跟踪请求的源|string|""||medium|
|connections.max.idle.ms|在这个配置的毫秒后关闭idle的conneciton|long|540000||medium|
|linger.ms|producer会将任何在两次请求传输之间到来的消息打包到同一个batch 请求中。一般情况下，这只会发生在消息到达的速度大于它们被发送的速度的情况下。然而在一些情况下，客户端可能希望即使在中等负载的情况下也降低请求的次数。这个配置通过增加小量的"假延迟"来达到这样的效果。即，比起立即发送一条消息，producer会等待给定的一段延迟时间，允许其他消息能够被发送，这样这些消息就可以batch到一起了。这可以被认为是模仿TCP中的Nagle算法。这个设置给出了batching的延迟上限：一旦我们得到了一个分区的batch.size大小的消息集合，producer会忽略这个设置立即发送这个batch到server，但是如果没有到达batch.size的数据量，我们会'逗留'这个选项指定的时间，等待更多的消息到来一起打包。这个设置默认为0（也就是不延迟）。例如，设置linger.ms=5，会有降低发送请求次数的效果，但是会在任何负载的情况下消息都会有5毫秒的延迟|long|0|[0,...]|medium|
|max.block.ms|这个设置指定了KafkaProducer.send()和KafkaProducer.partitionsFor()会阻塞多长时间。这些方法被阻塞的原因要么是buffer满了，要么是元数据（offset）不可用。在用户提供的serializers或者partitioner上的阻塞不算在这个超时时间内。|long|60000|[0,...]|medium|
|max.request.size|一个请求的最大字节数。这也是消息大小的有效上限。需要注意的是，server自己的消息大小上限可能和这个值不同。这个设置会限制producer在你单次请求中发送的消息batch数，以避免发送太大的请求。|int|1048576|[0,...]|medium|
|partitioner.class|实现了Partitioner接口的Partitioner类|class|class org.apache.kafka.clients.producer.internals.DefaultPartitioner||萌medium|
|receive.buffer.bytes|读取数据是的TCP receive buff（SO_RECVBUF）大小|int|32768|[0,...]|medium|
|request.timeout.ms|这个设置指定了客户端等待请求相应的最大时间。如果在这个超时时间内没有收到请求相应，客户端会重试或在retries到达时失败。|int|30000|[0,...]|medium|
|sasl.kerberos.service.name|||||medium|
|sasl.mechanism|||||medium|
|security.protocol||string|PLAINTEXT||medium|
|send.buffer.bytes|用于发送数据的TCP send buffer（SO_SNDBUF）大小|int|131072|[0,...]|medium|
|ssl.enable.protocols|||||medium|
|ssl.keystore.type|||||medium|
|ssl.protocol|||||medium|
|ssl.provider|||||medium|
|ssl.truststore.type|||||medium|
|timeout.ms|这个设置给出了server等待从followers返回producer用acks属性设置的确认要求的最大等待时间。如果这个时间到达却没有达到要求的确认数，会返回错误。这个超时时间是在server端测量，不包括请求的网络延迟。|int|30000|[0,...]|medium|
|block.on.buffer.full|当内存缓冲区耗尽我们必须停止接收新的消息（阻塞）或者抛出错误。默认情况下这个设置是false，producer不会抛出一个BufferExhaustException，而是会使用max.block.ms值去阻塞，这这个超时时间后会抛出TimeoutException异常。将这个值设为true会将max.block.ms设为Long.MAX_VALUE。同时如果这个属性为设为true，metadata.fetch.timeout.ms也将不再有效。这个参数已经是**deprecated**，并且会在未来的版本中移除。应该使用max.block.ms代替这个选项。|boolean|false||low|
|interceptor.classes|一个被用作拦截器的类的列表。实现ProducerInterceptor接口允许你在被发布到cluster之前去去拦截（或转化）producer收到的消息。默认没有使用拦截器。|list|null||low|
|max.in.flight.requests.per.connection|阻塞之前客户端在单个连接上将要发送的未被确认的请求的最大数量。需要注意的是，如果这个参数被设置为大于1并且有有发送失败发生，则有消息由于重试乱序的分先发生（如果retries被启用）|int|5|[1,...]|low|
|metadata.fetch.timeout.ms|数据第一次被发送给一个topic时我们必须fetch这个topic的元数据，以获知哪些server包含这个topic的分区。超时时间过后会抛异常返回给客户端。|long|60000|[0,...]|low|
|metadata.max.age.ms|在这个时间过后我们会强制一个元数据刷新，机制我们还没有看到任何分区leadership变化，这是为了前摄地发现任何新的brokers或分区|long|300000|[0,...]|low|
|metric.reporters|一个作为metrics reports的class列表。实现MetricReporter接口可以插入相应的metric report类负责新的metric创建。JmxReporter总是被包含去注册JMX统计信息。|list|[]||low|
|metrics.num.samples|计算metrics维护的抽样数量。|int|2|[1,...]|low|
|metrics.sample.window.ms|||||low|
|reconnect.backoff.ms|尝试去重新连接到一个给定的主机之前的等待时间。这个设置为了避免频繁重试连接到主机。这个等待时间也用于consumer发送给broker的所有请求|long|50|[0,...]|low|
|sasl.kerberos.kinit.cmd|||||low|
|sasl.kerberos.min.time.before.relogin|||||low|
|sasl.kerberos.ticket.renew.jitter|||||low|
|sasl.kerberos.ticket.renew.window.factor|||||low|
|ssl.cipher.suites|||||low|
|ssl.endpoint.identification.algorithm|||||low|
|ssl.keymanager.algorithm|||||low|
|ssl.trustmanager.algorithm|||||low|

对于那些对遗留的Scala producer配置项感兴趣的用户，可以在[这里](http://kafka.apache.org/082/documentation.html#producerconfigs)找到相关信息。