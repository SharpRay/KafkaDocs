# New Consumer配置

从0.9.00版本开始，我们已经给出了代替老的简单consumer API和高级consumer API的新的API。新的API被认为是beta版本的。下面是新的consumer的配置项：

| Name | Description | Type | Default | Valid Values | Importance |
| --- | --- | --- | --- | --- | --- |
| bootstrap.servers | 一个host\/port对列表，用于创建到Kafka cluster的初始连接。客户端会使用所有的Kafka servers，而不只是这个选项中列出的用于初始化立连接的servers。这个列表只是用于发现完整servers集合的初始化主机集合。这个列表的形式为host1:port1,host2:port2,...。由于这些server只是用于初始化连接发现完完整集群（可能会动态变化）的，因此这个列表没必要包含所有的server（你可能想要指定多于一个server，以防server宕机） | list |  |  | high |
| key.serializer | key的实现了Serializer接口的Serializer类 | class |  |  | high |
| value.serializer | value的实现了Serializer接口的Serializer类 | class |  |  | high |
| fetch.min.bytes | server应返回一个fetch请求的最小字节数。如果返回的数据量不够，请求会等待更多的数据到来。默认的1个字节意味着fetch请求只要有一个字节的数据可用就被响应或者fetch请求等待数据超时。设为大于1的值会导致server等待更大量的数据，这会改善一点server的吞吐，代价是附加的延迟。 | int | 1 | \[0,...\] | high |
| group.id | 用来标记这个consumer从属的consumer group的唯一字符串。如果consumer用subscribe\(topic\)或者基于Kafka的offset管理来使用group管理功能，则这个属性是必须的 | string | "" |  | high |
| heartbeat.interval.ms | 使用Kafka的group管理功能时希望的发送给consumer coordinator的心跳时间间隔。心跳用于保证consumer的session保持活动并且在新的consumer加入或离开consumer group时做rebalance。这个值必须要设置成小于session.timeout.ms。但是一般应该设置为不高于session.time.ms的1\/3。它可以被设置的更低，以控制用于期望rebalance的时间 | int | 3000 |  | high |
| max.partition.fetch.bytes | fetch数据时，server返回的每个分区的最大数据量。用于一次请求的最大的内存是\#partitions \* max.partition.fetch.bytes。这个参数值的大小必须至少是server端配置的最大单条消息大小，否则producer可能会产生大小大于consumer能消费的日志。如果发生这种情况，consumer会在一个特定的partition上师徒fetch一个大消息时卡住。 | int | 1048576 | \[0,...\] | high |
| session.timeout.ms | 使用Kafka的group管理功能时用来检测失败的超时时间。当在这个session超市是时间内没有收到consumer的心跳，broker会将这个consumer标记为失败并rebalance这个consumer所在的group。由于心跳只有在poll\(\)被调用的时候被发送，一个较长的session超时时间允许在consumer的poll循环中有更多的消息处理的时间，代价是更长的监测硬件失效的时间。也可以看下max.poll.records参数，也是用来控制在poll循环中的处理时间的选项。需要注意的是，这个选项的值必须是在broker端配置的group.min.session.timeout.ms和group.max.session.timeout.ms的范围内。 | int | 30000 |  | high |
| ssl.key.password |  |  |  |  | high |
| ssl.keystore.location |  |  |  |  | high |
| ssl.keystore.password |  |  |  |  | high |
| ssl.truststore.location |  |  |  |  | high |
| ssl.truststore.password |  |  |  |  | high |
| auto.offset.reset | 在Kafka中没有初始offset时或者当前offset在server中已不存在（例如，由于数据被删除）时的做法： **earliest**：自动将offset重置成最开始的offset； **latest**：自动将offset重置成最近的offset； **none**：如果找不到consumer group之前的offset抛异常； **anything else**：向consumer抛异常 | string | latest | \[latest,earliest,none\] | medium |
|connections.max.idle.ms|指定了关闭idle连接前的毫秒数|long|540000||medium|
|enable.auto.commit|如果为true则consumer的offset会在后台周期性的提交给broker|boolean|true||medium|
|exclude.internal.topics|内部topics（如offsets）中的记录是否暴露给consumer。如果设置为true，则从一个内部topic收到消息的唯一方法是是订阅它。|boolean|true||medium|
|max.poll.records|一个poll()调用返回的最大记录数。|int|2147483647|[1,...]|medium|
|partition.assignment.strategy|客户端用于在consumer实例中分配分区所有权的分区指派策略的class名称。|list|[org.apache.kafka.clients.consumer.RangeAssignor]||medium|
|receive.buffer.bytes|读取数据时使用的TCP receive buffer（SO_RECVBUF）的大小|int|65536|[0,...]|medium|
|request.timeout.ms|指定了客户端等待一个请求响应的最大时间。如果在这个超超时时间内没有收到响应，客户端会重新发送请求或者在重试次数过后返回失败。|int|40000|[0,...]|medium|
|sasl.kerberos.service.name|||||medium|
|sasl.mechanism|||||medium|
|security.protocol|||||medium|
|send.buffer.bytes|发送数据的TCP send buffer（SO_SNDBUF）大小|int|131072|[0,...]|medium|
|ssl.enabled.protocols|||||medium|
|ssl.keystore.type|||||medium|
|ssl.protocol|||||medium|
|ssl.provider|||||medium|
|ssl.truststore.type|||||medium|
|auto.commit.interval.ms|consumer的offsets自动提交到Kafka的频率（如果(enable.auto.commit设置为true）|long|5000|[0,...]|low|
|check.crcs|是否自动检查消费的记录的CRC32。这保证没有内存或磁盘中的消息损坏发生。这个检查增加了一些开销，因此在追求极致性能的场景下要禁用它。|boolean|true||low|
|client.id|提交请求时传给server的id字符串。目的是提供不只是用ip/port来跟踪请求源的方式，通过在server端请求日志中包含一个逻辑应用程序名称。|string|""||low|
|fetch.max.wait.ms|在没有足够的数据立即满足fetch.min.bytes设置的值的情况下，在应答fetch请求之前server端阻塞的总时间。|int|500|[0,...]|low|
|interceptor.classes|||||low|
|metadata.max.age.ms|||||low|
|metric.reporters|||||low|
|metrics.num.samples|||||low|
|metrics.sampple.window.ms|||||low|
|reconnect.backoff.ms|||||low|
|sasl.kerberos.kinit.cmd|||||low|
|sasl.kerberos.min.time.before.relogin|||||low|
|sasl.kerberos.ticket.renew.jitter|||||low|
|sasl.kerberos.ticket.renew.window.factor|||||low|
|ssl.cipher.suites|||||low|
|ssl.endpoint.identification.algorithm|||||low|
|ssl.keymanager.algorithm|||||low|
|ssl.trustmanager.algorithm|||||low|

