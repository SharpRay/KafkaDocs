# Broker配置

必须的配置如下：

* broker.id
* log.dirs
* zookeeper.connect

Topic级别的配置项以及默认值下面会详细讨论。

| Name | Description | Type | Default | Valid Values | Importance |
| --- | --- | --- | --- | --- | --- |
| zookeeper.connect | Zookeeper主机字符串 | string |  |  | high |
|listeners|Listener列表 - 逗号分隔的监听的URIs以及它们的协议。指定hostname为0.0.0.0会绑定到所有网络接口。hostname留空会绑定到默认网络接口。下面是合法的listeners列表示例：PLAINTEXT://myhost:9092,TRACE://:9091,PLAINTEXT://0.0.0.0:9092,TRACE://localhost:9093|string|null||high|
| advertized.host.name | DEPRECATED：只有在'advertised.listeners'或'listeners'没有设置的情况下使用。使用'advertised.listeners'代替这个属性。提交给ZooKeeper的主机名供客户端使用。在IaaS环境中，主机名可能需要金额broker绑定的接口名不同。如果这个属性没有设置，它会在'hot.name'设置的情况下使用'host.name'的值，否则使用java.net.InetAddress.getCanonicalHostName\(\)的返回值。 | string | null |  | high |
| advertized.listeners | 提交给Zookeeper的listeners供客户端使用，如果不同于前面的listeners（在server.properties中设置的listeners，格式为protocol://host:port，例如PLAINTEXT://:9083）。在IaaS环境中，这可能需要不同于broker绑定的接口设置。如果没有设置，则使用'listeners'的值。 | string | null | | high |
| advertized.port | DEPRECATED：只在'advertized.listeners'和'listeners'没有设置的情况下使用。使用'advertized.listeners'代替这个属性。端口会提交给Zookeeper供客户端使用。在IaaS环境中，这可能需要不同于broker绑定的端口。如果没有设置，会提交和broker绑定相同的端口。 | int | null || high |
| auto.create.topics.enable | 在服务上开启自动创建topic | boolean | true |  | high |
|auto.leader.rebalance.enable|开启自动leader负载均衡。一个后台运行的线程会在有规律的时间间隔内在检查并在需要的时候触发leader负载均衡|boolean|true||high|
|background.threads|用于执行多个后台处理任务的线程数|int|10|[1,...]|high|
|broker.id|服务的broker id。如果没有设置，会自动生成一个唯一的broker id。为了避免zookeeper生成的broker id和用户配置的broker id之间的冲突，生成的broker id从reserved.broker.max.id+1开始。|int|-1||high|
|compression.type|指定一个给定的topic的压缩类型。这个配置接受标准的压缩算法（'gzip', 'snappy', 'lz4'）。除此之外还接受'uncompressed'相当于不压缩；以及'producer'，也就是保持和producer设置的压缩算法一致。|string|producer||high|
|delete.topic.enable|开启删除topic。如果这个设置关闭则通过管理工具删除topic不会生效。|boolean|false||high|
|host.name|DEPRECATED：只有在'listeners'没有设置的情况下使用。使用'listeners'代替这个属性。broker的hostname。如果设置，则broker只会绑定到这个地址。如果没有设置，broker会绑定到所有网络接口。|string|""||high|
|leader.imbalance.check.interval.seconds|由控制器触发的分区rebalance检查的频率。|long|300||high|
|leader.imbalance.per.broker.percentage|每个broker允许的leader负载不均衡的比率。如果每个broker大于这个值则控制器会触发一个leader balance。这个值是比率。|int|10||high|
|log.dir|日志数据保存的目录（作为log.dirs属性的补充）。|string|/tmp/kafka-logs||high|
|log.dirs|日志数据保存的目录集合。如果没有设置，则使用log.dir的设置|string|null||high|
|log.flush.interval.messages|消息flush到磁盘之前可以在一个日志分区上累积的消息数量。|long|9223372036854775807|[1,...]|high|
|log.flushj.interval.ms|任何topic中的一条日志在flush到磁盘之前在内存中保留的最长时间。如果没有设置，则使用log.flush.scheduler.interval.ms的值|long|null||high|
|log.flush.offset.checkpoint.interval.ms|更新上一次数据flush到磁盘行为的频率，作为日志恢复检查点。|int|60000|[0,...]|high|
|long.flush.scheduler.interval.ms|log flusher用来检查是否有日志需要被flush到磁盘的频率。|long|9223372036854775807||high|
|log.retention.bytes|删除之前保存的最大日志大小。|long|-1||high|
|log.retention.hours|删除之前保存日志的小时数。|int|168||high|
|log.retention.minutes|删除之前保存日志的分钟数，如果没有设置，使用log.retention.hours的值|int|null||high|
|log.retention.ms|删除之前保存日志的毫秒数。如果没有设置，使用log.retention.minutes的值|long|null||high|
|log.roll.hours|一个log segment关闭（并新建一个segment）前的最大小时数|int|168|[1,...]|high|
|log.roll.jitter.hours|从logRollTimeMillis中抽离的jitter的最大小时数|int|0|[0,...]|high|
|log.roll.jitter.ms|从logRollTimeMillis中抽离的jitter的最大毫秒数|long|null||high|
|log.roll.ms|一个log segment关闭（并新建一个segment）前的最大毫秒数。如果没有设置，使用Log.roll.hours的值|long|null||high|
|log.segment.bytes|一个log文件的最大大小|int|1073741824|[14,...]|high|
|log.segment.delete.delay.ms|从文件系统中删除一个文件等待的最长时间|long|60000|[0,...]|high|
|message.max.bytes|server能够接收的单挑日志的最大字节数|int|1000012|[0,...]|high|
|min.insync.replicas|定义了ISR中需要满足带有acks=all(或者-1)的producer请求的replicas的最小数量|int|1|[1,...]|high|
|num.io.threads|server用来完成网络请求的io线程数|int|8|[1,...]|high|
|num.network.threads|server用来处理网络请求的网络线程数|int|3|[1,...]|high|
|num.recovery.threads.per.data.dir|每个数据目录用来在启动时恢复数据和在关闭时flush数据的线程数|int|1|[1,...]|high|
|num.replica.fetchers|用来从一个source broker复制消息的fetch线程数。增加这个属性的值可以增加follower broker的I/O并行度|int|1||high|
|offsets.metadata.max.bytes|和一个offset提交相关的metadata条目的最大字节数|int|4096||high|
|offset.commit.required.acks|offset提交被接受能够被接受之前需要的ack数量，这里不应该覆盖默认值（-1）|short|-1||high|
|offsets.commit.timeout.ms|offset提交会被延迟，直到offsets topic的所有replicas收到提交或这个属性指定的时间到达。这和producer请求超时类似|int|5000|[1,...]|high|
|offsets.load.buffer.size|加载offsets进缓存时，从offsets文件（segments）读取的批量数据大小|int|5242880|[1,...]|high|
|offsets.retention.check.interval.ms|检查陈旧offsets的频率|long|600000|[1,...]|high|
|offsets.retention.minutes|offsets topic的日志保留窗口时间|int|1440|[1....]|high|
|offsets.topic.compression.codec|用于offsets topic的压缩算法 - 压缩可用于得到"原子"提交|int|0||high|





