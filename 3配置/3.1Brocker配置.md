# Broker配置

必须的配置如下：

* broker.id
* log.dirs
* zookeeper.connect

Topic级别的配置项以及默认值下面会详细讨论。

| Name | Description | Type | Default | Valid Values | Importance |
| --- | --- | --- | --- | --- | --- |
| zookeeper.connect | Zookeeper主机字符串 | string |  |  | high |
|listeners|Listener列表 - 逗号分隔的监听的URIs以及它们的协议。指定hostname为0.0.0.0会绑定到所有网络接口。hostname留空会绑定到默认网络接口。下面是合法的listeners列表示例：PLAINTEXT://myhost:9092,TRACE://:9091,PLAINTEXT://0.0.0.0:9092,TRACE://localhost:9093|string|null||high|
| advertized.host.name | DEPRECATED：只有在'advertised.listeners'或'listeners'没有设置的情况下使用。使用'advertised.listeners'代替这个属性。提交给ZooKeeper的主机名供客户端使用。在IaaS环境中，主机名可能需要金额broker绑定的接口名不同。如果这个属性没有设置，它会在'hot.name'设置的情况下使用'host.name'的值，否则使用java.net.InetAddress.getCanonicalHostName\(\)的返回值。 | string | null |  | high |
| advertized.listeners | 提交给Zookeeper的listeners供客户端使用，如果不同于前面的listeners（在server.properties中设置的listeners，格式为protocol://host:port，例如PLAINTEXT://:9083）。在IaaS环境中，这可能需要不同于broker绑定的接口设置。如果没有设置，则使用'listeners'的值。 | string | null | | high |
| advertized.port | DEPRECATED：只在'advertized.listeners'和'listeners'没有设置的情况下使用。使用'advertized.listeners'代替这个属性。端口会提交给Zookeeper供客户端使用。在IaaS环境中，这可能需要不同于broker绑定的端口。如果没有设置，会提交和broker绑定相同的端口。 | int | null || high |
| auto.create.topics.enable | 在服务上开启自动创建topic | boolean | true |  | high |
|auto.leader.rebalance.enable|开启自动leader负载均衡。一个后台运行的线程会在有规律的时间间隔内在检查并在需要的时候触发leader负载均衡|boolean|true||high|
|background.threads|用于执行多个后台处理任务的线程数|int|10|[1,...]|high|
|broker.id|服务的broker id。如果没有设置，会自动生成一个唯一的broker id。为了避免zookeeper生成的broker id和用户配置的broker id之间的冲突，生成的broker id从reserved.broker.max.id+1开始。|int|-1||high|
|compression.type|指定一个给定的topic的压缩类型。这个配置接受标准的压缩算法（'gzip', 'snappy', 'lz4'）。除此之外还接受'uncompressed'相当于不压缩；以及'producer'，也就是保持和producer设置的压缩算法一致。|string|producer||high|
|delete.topic.enable|开启删除topic。如果这个设置关闭则通过管理工具删除topic不会生效。|boolean|false||high|
|host.name|DEPRECATED：只有在'listeners'没有设置的情况下使用。使用'listeners'代替这个属性。broker的hostname。如果设置，则broker只会绑定到这个地址。如果没有设置，broker会绑定到所有网络接口。|string|""||high|
|leader.imbalance.check.interval.seconds|由控制器触发的分区rebalance检查的频率。|long|300||high|
|leader.imbalance.per.broker.percentage|每个broker允许的leader负载不均衡的比率。如果每个broker大于这个值则控制器会触发一个leader balance。这个值是比率。|int|10||high|
|log.dir|日志数据保存的目录（作为log.dirs属性的补充）。|string|/tmp/kafka-logs||high|
|log.dirs|日志数据保存的目录集合。如果没有设置，则使用log.dir的设置|string|null||high|
|log.flush.interval.messages|消息flush到磁盘之前可以在一个日志分区上累积的消息数量。|long|9223372036854775807|[1,...]|high|
|log.flushj.interval.ms|任何topic中的一条日志在flush到磁盘之前在内存中保留的最长时间。如果没有设置，则使用log.flush.scheduler.interval.ms的值|long|null||high|
|log.flush.offset.checkpoint.interval.ms|更新上一次数据flush到磁盘行为的频率，作为日志恢复检查点。|int|60000|[0,...]|high|
|long.flush.scheduler.interval.ms|log flusher用来检查是否有日志需要被flush到磁盘的频率。|long|9223372036854775807||high|
|log.retention.bytes|删除之前保存的最大日志大小。|long|-1||high|
|log.retention.hours|删除之前保存日志的小时数。|int|168||high|
|log.retention.minutes|删除之前保存日志的分钟数，如果没有设置，使用log.retention.hours的值|int|null||high|
|log.retention.ms|删除之前保存日志的毫秒数。如果没有设置，使用log.retention.minutes的值|long|null||high|
|log.roll.hours|一个log segment关闭（并新建一个segment）前的最大小时数|int|168|[1,...]|high|
|log.roll.jitter.hours|从logRollTimeMillis中抽离的jitter的最大小时数|int|0|[0,...]|high|
|log.roll.jitter.ms|从logRollTimeMillis中抽离的jitter的最大毫秒数|long|null||high|
|log.roll.ms|一个log segment关闭（并新建一个segment）前的最大毫秒数。如果没有设置，使用Log.roll.hours的值|long|null||high|
|log.segment.bytes|一个log文件的最大大小|int|1073741824|[14,...]|high|
|log.segment.delete.delay.ms|从文件系统中删除一个文件等待的最长时间|long|60000|[0,...]|high|
|message.max.bytes|server能够接收的单挑日志的最大字节数|int|1000012|[0,...]|high|
|min.insync.replicas|定义了ISR中需要满足带有acks=all(或者-1)的producer请求的replicas的最小数量|int|1|[1,...]|high|
|num.io.threads|server用来完成网络请求的io线程数|int|8|[1,...]|high|
|num.network.threads|server用来处理网络请求的网络线程数|int|3|[1,...]|high|
|num.recovery.threads.per.data.dir|每个数据目录用来在启动时恢复数据和在关闭时flush数据的线程数|int|1|[1,...]|high|
|num.replica.fetchers|用来从一个source broker复制消息的fetch线程数。增加这个属性的值可以增加follower broker的I/O并行度|int|1||high|
|offsets.metadata.max.bytes|和一个offset提交相关的metadata条目的最大字节数|int|4096||high|
|offset.commit.required.acks|offset提交被接受能够被接受之前需要的ack数量，这里不应该覆盖默认值（-1）|short|-1||high|
|offsets.commit.timeout.ms|offset提交会被延迟，直到offsets topic的所有replicas收到提交或这个属性指定的时间到达。这和producer请求超时类似|int|5000|[1,...]|high|
|offsets.load.buffer.size|加载offsets进缓存时，从offsets文件（segments）读取的批量数据大小|int|5242880|[1,...]|high|
|offsets.retention.check.interval.ms|检查陈旧offsets的频率|long|600000|[1,...]|high|
|offsets.retention.minutes|offsets topic的日志保留窗口时间|int|1440|[1....]|high|
|offsets.topic.compression.codec|用于offsets topic的压缩算法 - 压缩可用于得到"原子"提交|int|0||high|
|offsets.topic.num.partitions|offsets topic的分区数（部署后不能修改）|int|50|[1,...]|high|
|offsets.topic.replication.factor|offsets topic的副本数（设置的高一些以保证可用性）。为了保证offsets topic有效的副本数为配置的值，存活的brokers数量必须至少是对offsets topic第一次请求时的副本数量（例如，第一次提交请求时存offsets topic的副本数量为3，那么存货的brokers至少也是3）。否则，要么创建offsets topic失败，或者会得到min(存活的brokers，配置的副本数)个副本|short|3|[1,...]|high|
|offsets.topic.segment.bytes|为了便于更快的日志压缩和缓存加载，offsets topic segment字节数应保持一个较小的了量级|int|104857600|[1,...]|high|
|port|DEPRECATED：只有在'listeners'没有设置时使用。使用'listeners'代替这个属性。监听和接受请求的端口|int|9092||high|
|queued.max.requests|阻塞网络线程之前允许请求的最大队列数。|int|500|[1,...]|high|
|quota.consumer.default|任何以clientId/consumer group识别的consumer，如果每秒fetch的字节数超过这个值会被截流。|long|9223372036854775807|[1,...]|high|
|quota.producer.default|任何以clientId识别的producer，如果每秒产生的字节数大于这个值会被截流。|long|9223372036854775807|[1,...]|high|
|replica.fetch.max.bytes|尝试fetch的消息的最大字节数|int|1048576||high|
|replica.fetch.min.bytes|尝试fetch的消息的最小字节数。如果请求返回的字节数不够，等到replicaMaxWaitTimeMs返回。|int|1||high|
|replica.fetch.wait.max.ms|follower replicas发出的每个fetcher请求的最大等待时间。这个值应该总是小于replica.lag.time.max.ms，以防止低吞吐的topics的ISR频繁减少。|int|500||high|
|replica.high.watermark.checkpoint.interval.ms|replica存储各自的high watermark到磁盘的频率。|long|5000||high|
|replica.lag.time.max.ms|在这个时间内，如果一个follower没有发出任何fetch请求或者没有消耗到leaders日志的结束offset，leader会从isr中将这个follower移除。|long|10000||high|
|replica.socket.receive.buffer.bytes|用于网络请求的socket接受数据的buffer大小|int|65536||high|
|replica.socket.timeout.ms|网络请求的超时时间。这个值必须至少是replica.fetch,wait.max.ms|int|30000||high|
|request.timeout.ms|客户端等待请求响应最大时间由这个配置指定。如果在这个时间内没有收到响应，则客户端会重发请求或在超过重试次数的情况下失败。|int|30000||high|
|socket.receive.buffer.bytes|socket server sockets的SO_RECVBUF。|int|102400||high|
|socket.request.max.bytes|一个socket请求的最大字节数|int|104857600|[1,...]|high|
|socket.send.buffer.bytes|socket server sockets的SO_SNDBUF。|int|102400||high|
|unclean.leader.election.enable|是否启用将不在ISR中的replicas选举为leader作为最后的手段，尽管这么做会导致数据丢失|boolean|true||high|
|zookeeper.connection.timeout.ms|客户端等待和zookeeper建立连接的最长时间。如果不设置，则使用zookeeper.session.timeout.ms的值|int|null||high|
|zookeeper.session.timeout.ms|zookeeper session超时时间|int|6000||high|
|zookeeper.set.acl|设置client使用安全ACLs|boolean|false||high|
|broker.id.generation.enable|是否启用servert端自动生成broker id。如果启用则reserved.broker.max.id的值会参与生成broker id。|boolean|true||medium|
|broker.rack|broker所在机架。这个属性会用于机架发现复制，用于容错。例如：'RACK1','us-est-1d'|string|null||medium|
|connections.max.idle.ms|idle连接超时：server socket处理线程会在连接idle超过这个时间后关闭连接|long|600000||medium|
|controlled_shutdown.enable|启用server的控制关闭|boolean|true||medium|
|controlled.shutdown.max.retries|控制关闭会有很多失败原因。这个属性决定了了失败的重试次数。|int|3||medium|
|controlled.shutdown.retry.backoff.ms|每次充实前，系统需要时间从导致上一次失败的状态中恢复（controller失效恢复，replica延迟等等）。这个设置决定在重试之前等待的时间。|long|5000||medium|
|controller.socket.timeout.ms|用于controller-to-broker通道的socket超时时间|int|30000||medium|
|default.replication.factor|自动创建topics的默认副本数|int|1||medium|
|fetch.purgatory.purge.interval.requests||int|1000||medium|
|group.max.session.timeout.ms|用于注册consumers的最大允许的session超时时间。更长的超时时间给予consumers更长的时间去处理心跳之间的消息，代价是更长的监测错误的时间。|int|300000||medium|
|group.min.session.timeout.ms|用于注册consumers的允许的最短session超时时间。更短的超时时间会导致更快的错误监测时间，代价是更频繁的consumer心跳，这会会用光broker资源|int|6000||medium|
|inter.broker.protocol.version|使用哪个版本的broker间协议。这个版本号会在所有brokers升级到新版本时增加。下面是一些合法的值：0.8.0,0.8.1,0.8.2,0.8.2.0,0.8.2.1,0.9.0.0,0.9.0.1。查看ApiVersion获取完成版本列表|string|0.10.0-IV1||medium|
|log.cleaner.backoff.ms|没有需要清除的日志的休眠时间。|long|15000|[0,...]|medium|
|lopng.cleaner.dedupe.buffer.size|用于所有清除线程的删除重复数据的内存大小|long|134217728||medium|
|log.cleaner.delete.retention.ms|已删除数据的保留时间|86400000|||medium|
|log.cleaner.enable|启用运行在server上的日志清除进程。如果使用任何带有cleanup.policy=compact选项的topics，那么这个选项应该启用。如果禁用，使用compact的topics不会被压缩并且大小会持续增加。|boolean|true||medium|
|log.cleaner.io.buffer.load.factor|日志清除进程的删除重复数据的缓冲加载系数。更高的值可以一次清除更多日志，但是会导致更多的哈希碰撞。|double|0.9||medium|
|log.cleaner.io.buffer.size|所有cleaner线程共享的用于日志清除I/O缓冲区的内存大小|int|524288|[0,...]|medium|
|log.cleaner.io.max.bytes.per.second|log cleaner会被截流，它的每秒平均读写I/O不能超过这个值|double|1.7976931348623157E308||medium|
|log.cleaner.min.cleanable.ratio|脏日志和所有日志的最小的比率，达到这个比率cleaner才会清除数据。|double|0.5||medium|
|log.cleaner.threads|用于日志清除的后台线程数|int|1|[0,...]|medium|
|log.cleanup.policy|数据保留窗口过后，segments默认的清除规则，必须是"delete"或者"compact"|string|delete|[compact, delete]|medium|
|log.index.interval.bytes|增加一个条目到offset的间隔|int|4096|[0,...]|medium|
|log.index.size.max.bytes|offset索引最大的字节数|int|10485760|[4,...]|medium|
|log.message.format.version||string|0.10。0-IV1||medium|
|long.message.timestamp.difference.max.ms|broker收到消息的时间戳和日志中指定的时间戳的最大间隔。如果message.timestamp.type=CreateTime，那么一个消息会在时间间隔大于这个值的时候被抛弃。如果message.timestamp.type=LogAppendTime，则这个值被忽略|long|9223372036854775807|[0,...]|medium|
|log.message.timestamp.type|定义message中的时间戳为message生成的时间还是log加载到broker的时间。值必须为'CreateTime'或‘LogAppendTime’|string|CreateTime|[CreateTim, LogAppendTime]|medium|
|log.preallocate|创建新segment时是否预分配文件。如果你在windows上使用Kafka，这个值要设为true。|boolean|false||medium|
|log.retention.check.interval.ms|log cleaner检查日志是否有需要删除的时间间隔|long|300000|[1,...]|medium|
|max.connections.per.ip|从每个ip地址来的最大的连接数|int|2147483647|[1,...]|medium|
|max.connections.per.ip.overrides||string|""||medium|
|num.partitions|每个topic默认的日志分区数|int|1|[1,...]|medium|
|principal.builder.class|||||medium|
|producer.purgatory.purge.interval.requests|||||medium|
|replica.fetch.backoff.ms|fetch分区发生错误的休眠时间|int|1000||medium|
|reserved.broker.max.id|能够用于broker.id的最大值|int|1000|[0,...]|medium|
|sasl.enable.mechanisms|||||medium|
|sasl.kerberos.kinit.cmd|||||medium|
|sasl.kerberos.min.time.before.relogin|||||medium|
|sasl.kerberos.principal.to.local.rules|||||medium|
|sasl.kerberos.service.name|||||medium|
|sasl.kerberos.ticket.renew.jitter|||||medium|
|sasl.kerberos.ticket.renew.window.factor|||||medium|
|sasl.mechanism.inter.broker.protocol|||||medium|
|security.inter.broker.protocol|broker间通信的安全协议。合法值有：PLAINTET,SSL,SASL_PLAINTEXT.SASL_SSL|string|PLAINTEXT||medium|
|ssl.cipher.suites|||||medium|
|ssl.client.auth|||||medium|
|ssl.enabled.protocols|||||medium|
|ssl.key.password|||||medium|
|ssl.keymanager.algorithm|||||medium|
|ssl.keystore.location|||||medium|
|ssl.keystore.password|||||medium|
|ssl.keystore.type|||||medium|
|ssl.protocol|||||medium|
|ssl.provider|||||medium|
|ssl.trustmanager.algorithm|||||medium|
|ssl.truststore.location|||||medium|
|ssl.truststore.password|||||medium|
|ssl.truststore.type|||||medium|
|authorizer.class.name|||||low|
|metric.reporters|||||low|
|metrics.num.samples|||||low|
|metrics.sample.window.ms|||||low|
|quota.window.num|||||low|
|quota.windowsize.seconds|||||low|
|ssl.endpoint.identification.algorithm|||||low|
|zookeeper.sync.time.ms|||||low|




