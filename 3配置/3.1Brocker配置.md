# Broker配置

必须的配置如下：

* broker.id
* log.dirs
* zookeeper.connect

Topic级别的配置项以及默认值下面会详细讨论。

| Name | Description | Type | Default | Valid Values | Importance |
| --- | --- | --- | --- | --- | --- |
| zookeeper.connect | Zookeeper主机字符串 | string |  |  | high |
| listeners | Listener列表 - 逗号分隔的监听的URIs以及它们的协议。指定hostname为0.0.0.0会绑定到所有网络接口。hostname留空会绑定到默认网络接口。下面是合法的listeners列表示例：PLAINTEXT:\/\/myhost:9092,TRACE:\/\/:9091,PLAINTEXT:\/\/0.0.0.0:9092,TRACE:\/\/localhost:9093 | string | null |  | high |
| advertized.host.name | DEPRECATED：只有在'advertised.listeners'或'listeners'没有设置的情况下使用。使用'advertised.listeners'代替这个属性。提交给ZooKeeper的主机名供客户端使用。在IaaS环境中，主机名可能需要金额broker绑定的接口名不同。如果这个属性没有设置，它会在'hot.name'设置的情况下使用'host.name'的值，否则使用java.net.InetAddress.getCanonicalHostName\(\)的返回值。 | string | null |  | high |
| advertized.listeners | 提交给Zookeeper的listeners供客户端使用，如果不同于前面的listeners（在server.properties中设置的listeners，格式为protocol:\/\/host:port，例如PLAINTEXT:\/\/:9083）。在IaaS环境中，这可能需要不同于broker绑定的接口设置。如果没有设置，则使用'listeners'的值。 | string | null |  | high |
| advertized.port | DEPRECATED：只在'advertized.listeners'和'listeners'没有设置的情况下使用。使用'advertized.listeners'代替这个属性。端口会提交给Zookeeper供客户端使用。在IaaS环境中，这可能需要不同于broker绑定的端口。如果没有设置，会提交和broker绑定相同的端口。 | int | null |  | high |
| auto.create.topics.enable | 在服务上开启自动创建topic | boolean | true |  | high |
| auto.leader.rebalance.enable | 开启自动leader负载均衡。一个后台运行的线程会在有规律的时间间隔内在检查并在需要的时候触发leader负载均衡 | boolean | true |  | high |
| background.threads | 用于执行多个后台处理任务的线程数 | int | 10 | \[1,...\] | high |
| broker.id | 服务的broker id。如果没有设置，会自动生成一个唯一的broker id。为了避免zookeeper生成的broker id和用户配置的broker id之间的冲突，生成的broker id从reserved.broker.max.id+1开始。 | int | -1 |  | high |
| compression.type | 指定一个给定的topic的压缩类型。这个配置接受标准的压缩算法（'gzip', 'snappy', 'lz4'）。除此之外还接受'uncompressed'相当于不压缩；以及'producer'，也就是保持和producer设置的压缩算法一致。 | string | producer |  | high |
| delete.topic.enable | 开启删除topic。如果这个设置关闭则通过管理工具删除topic不会生效。 | boolean | false |  | high |
| host.name | DEPRECATED：只有在'listeners'没有设置的情况下使用。使用'listeners'代替这个属性。broker的hostname。如果设置，则broker只会绑定到这个地址。如果没有设置，broker会绑定到所有网络接口。 | string | "" |  | high |
| leader.imbalance.check.interval.seconds | 由控制器触发的分区rebalance检查的频率。 | long | 300 |  | high |
| leader.imbalance.per.broker.percentage | 每个broker允许的leader负载不均衡的比率。如果每个broker大于这个值则控制器会触发一个leader balance。这个值是比率。 | int | 10 |  | high |
| log.dir | 日志数据保存的目录（作为log.dirs属性的补充）。 | string | \/tmp\/kafka-logs |  | high |
| log.dirs | 日志数据保存的目录集合。如果没有设置，则使用log.dir的设置 | string | null |  | high |
| log.flush.interval.messages | 消息flush到磁盘之前可以在一个日志分区上累积的消息数量。 | long | 9223372036854775807 | \[1,...\] | high |
| log.flushj.interval.ms | 任何topic中的一条日志在flush到磁盘之前在内存中保留的最长时间。如果没有设置，则使用log.flush.scheduler.interval.ms的值 | long | null |  | high |
| log.flush.offset.checkpoint.interval.ms | 更新上一次数据flush到磁盘行为的频率，作为日志恢复检查点。 | int | 60000 | \[0,...\] | high |
| long.flush.scheduler.interval.ms | log flusher用来检查是否有日志需要被flush到磁盘的频率。 | long | 9223372036854775807 |  | high |
| log.retention.bytes | 删除之前保存的最大日志大小。 | long | -1 |  | high |
| log.retention.hours | 删除之前保存日志的小时数。 | int | 168 |  | high |
| log.retention.minutes | 删除之前保存日志的分钟数，如果没有设置，使用log.retention.hours的值 | int | null |  | high |
| log.retention.ms | 删除之前保存日志的毫秒数。如果没有设置，使用log.retention.minutes的值 | long | null |  | high |
| log.roll.hours | 一个log segment关闭（并新建一个segment）前的最大小时数 | int | 168 | \[1,...\] | high |
| log.roll.jitter.hours | 从logRollTimeMillis中抽离的jitter的最大小时数 | int | 0 | \[0,...\] | high |
| log.roll.jitter.ms | 从logRollTimeMillis中抽离的jitter的最大毫秒数 | long | null |  | high |
| log.roll.ms | 一个log segment关闭（并新建一个segment）前的最大毫秒数。如果没有设置，使用Log.roll.hours的值 | long | null |  | high |
| log.segment.bytes | 一个log文件的最大大小 | int | 1073741824 | \[14,...\] | high |
| log.segment.delete.delay.ms | 从文件系统中删除一个文件等待的最长时间 | long | 60000 | \[0,...\] | high |
| message.max.bytes | server能够接收的单挑日志的最大字节数 | int | 1000012 | \[0,...\] | high |
| min.insync.replicas | 定义了ISR中需要满足带有acks=all\(或者-1\)的producer请求的replicas的最小数量 | int | 1 | \[1,...\] | high |
| num.io.threads | server用来完成网络请求的io线程数 | int | 8 | \[1,...\] | high |
| num.network.threads | server用来处理网络请求的网络线程数 | int | 3 | \[1,...\] | high |
| num.recovery.threads.per.data.dir | 每个数据目录用来在启动时恢复数据和在关闭时flush数据的线程数 | int | 1 | \[1,...\] | high |
| num.replica.fetchers | 用来从一个source broker复制消息的fetch线程数。增加这个属性的值可以增加follower broker的I\/O并行度 | int | 1 |  | high |
| offsets.metadata.max.bytes | 和一个offset提交相关的metadata条目的最大字节数 | int | 4096 |  | high |
| offset.commit.required.acks | offset提交被接受能够被接受之前需要的ack数量，这里不应该覆盖默认值（-1） | short | -1 |  | high |
| offsets.commit.timeout.ms | offset提交会被延迟，直到offsets topic的所有replicas收到提交或这个属性指定的时间到达。这和producer请求超时类似 | int | 5000 | \[1,...\] | high |
| offsets.load.buffer.size | 加载offsets进缓存时，从offsets文件（segments）读取的批量数据大小 | int | 5242880 | \[1,...\] | high |
| offsets.retention.check.interval.ms | 检查陈旧offsets的频率 | long | 600000 | \[1,...\] | high |
| offsets.retention.minutes | offsets topic的日志保留窗口时间 | int | 1440 | \[1....\] | high |
| offsets.topic.compression.codec | 用于offsets topic的压缩算法 - 压缩可用于得到"原子"提交 | int | 0 |  | high |
| offsets.topic.num.partitions | offsets topic的分区数（部署后不能修改） | int | 50 | \[1,...\] | high |
| offsets.topic.replication.factor | offsets topic的副本数（设置的高一些以保证可用性）。为了保证offsets topic有效的副本数为配置的值，存活的brokers数量必须至少是对offsets topic第一次请求时的副本数量（例如，第一次提交请求时存offsets topic的副本数量为3，那么存货的brokers至少也是3）。否则，要么创建offsets topic失败，或者会得到min\(存活的brokers，配置的副本数\)个副本 | short | 3 | \[1,...\] | high |
| offsets.topic.segment.bytes | 为了便于更快的日志压缩和缓存加载，offsets topic segment字节数应保持一个较小的了量级 | int | 104857600 | \[1,...\] | high |
| port | DEPRECATED：只有在'listeners'没有设置时使用。使用'listeners'代替这个属性。监听和接受请求的端口 | int | 9092 |  | high |
| queued.max.requests | 阻塞网络线程之前允许排队的最大请求数。 | int | 500 | \[1,...\] | high |
| quota.consumer.default | 任何以clientId\/consumer group识别的consumer，如果每秒fetch的字节数超过这个值会被截流。 | long | 9223372036854775807 | \[1,...\] | high |
| quota.producer.default | 任何以clientId识别的producer，如果每秒产生的字节数大于这个值会被截流。 | long | 9223372036854775807 | \[1,...\] | high |
| replica.fetch.max.bytes | 尝试fetch的消息的最大字节数 | int | 1048576 |  | high |
| replica.fetch.min.bytes | 尝试fetch的消息的最小字节数。如果请求返回的字节数不够，等到replicaMaxWaitTimeMs返回。 | int | 1 |  | high |
| replica.fetch.wait.max.ms | follower replicas发出的每个fetcher请求的最大等待时间。这个值应该总是小于replica.lag.time.max.ms，以防止低吞吐的topics的ISR频繁减少。 | int | 500 |  | high |
| replica.high.watermark.checkpoint.interval.ms | replica存储各自的high watermark到磁盘的频率。 | long | 5000 |  | high |
| replica.lag.time.max.ms | 在这个时间内，如果一个follower没有发出任何fetch请求或者没有消耗到leaders日志的结束offset，leader会从isr中将这个follower移除。 | long | 10000 |  | high |
| replica.socket.receive.buffer.bytes | 用于网络请求的socket接受数据的buffer大小 | int | 65536 |  | high |
| replica.socket.timeout.ms | 网络请求的超时时间。这个值必须至少是replica.fetch,wait.max.ms | int | 30000 |  | high |
| request.timeout.ms | 客户端等待请求响应最大时间由这个配置指定。如果在这个时间内没有收到响应，则客户端会重发请求或在超过重试次数的情况下失败。 | int | 30000 |  | high |
| socket.receive.buffer.bytes | socket server sockets的SO\_RECVBUF。 | int | 102400 |  | high |
| socket.request.max.bytes | 一个socket请求的最大字节数 | int | 104857600 | \[1,...\] | high |
| socket.send.buffer.bytes | socket server sockets的SO\_SNDBUF。 | int | 102400 |  | high |
| unclean.leader.election.enable | 是否启用将不在ISR中的replicas选举为leader作为最后的手段，尽管这么做会导致数据丢失 | boolean | true |  | high |
| zookeeper.connection.timeout.ms | 客户端等待和zookeeper建立连接的最长时间。如果不设置，则使用zookeeper.session.timeout.ms的值 | int | null |  | high |
| zookeeper.session.timeout.ms | zookeeper session超时时间 | int | 6000 |  | high |
| zookeeper.set.acl | 设置client使用安全ACLs | boolean | false |  | high |
| broker.id.generation.enable | 是否启用servert端自动生成broker id。如果启用则reserved.broker.max.id的值会参与生成broker id。 | boolean | true |  | medium |
| broker.rack | broker所在机架。这个属性会用于机架发现复制，用于容错。例如：'RACK1','us-est-1d' | string | null |  | medium |
| connections.max.idle.ms | idle连接超时：server socket处理线程会在连接idle超过这个时间后关闭连接 | long | 600000 |  | medium |
| controlled\_shutdown.enable | 启用server的控制关闭 | boolean | true |  | medium |
| controlled.shutdown.max.retries | 控制关闭会有很多失败原因。这个属性决定了了失败的重试次数。 | int | 3 |  | medium |
| controlled.shutdown.retry.backoff.ms | 每次充实前，系统需要时间从导致上一次失败的状态中恢复（controller失效恢复，replica延迟等等）。这个设置决定在重试之前等待的时间。 | long | 5000 |  | medium |
| controller.socket.timeout.ms | 用于controller-to-broker通道的socket超时时间 | int | 30000 |  | medium |
| default.replication.factor | 自动创建topics的默认副本数 | int | 1 |  | medium |
| fetch.purgatory.purge.interval.requests |  | int | 1000 |  | medium |
| group.max.session.timeout.ms | 用于注册consumers的最大允许的session超时时间。更长的超时时间给予consumers更长的时间去处理心跳之间的消息，代价是更长的监测错误的时间。 | int | 300000 |  | medium |
| group.min.session.timeout.ms | 用于注册consumers的允许的最短session超时时间。更短的超时时间会导致更快的错误监测时间，代价是更频繁的consumer心跳，这会会用光broker资源 | int | 6000 |  | medium |
| inter.broker.protocol.version | 使用哪个版本的broker间协议。这个版本号会在所有brokers升级到新版本时增加。下面是一些合法的值：0.8.0,0.8.1,0.8.2,0.8.2.0,0.8.2.1,0.9.0.0,0.9.0.1。查看ApiVersion获取完成版本列表 | string | 0.10.0-IV1 |  | medium |
| log.cleaner.backoff.ms | 没有需要清除的日志的休眠时间。 | long | 15000 | \[0,...\] | medium |
| lopng.cleaner.dedupe.buffer.size | 用于所有清除线程的删除重复数据的内存大小 | long | 134217728 |  | medium |
| log.cleaner.delete.retention.ms | 已删除数据的保留时间 | 86400000 |  |  | medium |
| log.cleaner.enable | 启用运行在server上的日志清除进程。如果使用任何带有cleanup.policy=compact选项的topics，那么这个选项应该启用。如果禁用，使用compact的topics不会被压缩并且大小会持续增加。 | boolean | true |  | medium |
| log.cleaner.io.buffer.load.factor | 日志清除进程的删除重复数据的缓冲加载系数。更高的值可以一次清除更多日志，但是会导致更多的哈希碰撞。 | double | 0.9 |  | medium |
| log.cleaner.io.buffer.size | 所有cleaner线程共享的用于日志清除I\/O缓冲区的内存大小 | int | 524288 | \[0,...\] | medium |
| log.cleaner.io.max.bytes.per.second | log cleaner会被截流，它的每秒平均读写I\/O不能超过这个值 | double | 1.7976931348623157E308 |  | medium |
| log.cleaner.min.cleanable.ratio | 脏日志和所有日志的最小的比率，达到这个比率cleaner才会清除数据。 | double | 0.5 |  | medium |
| log.cleaner.threads | 用于日志清除的后台线程数 | int | 1 | \[0,...\] | medium |
| log.cleanup.policy | 数据保留窗口过后，segments默认的清除规则，必须是"delete"或者"compact" | string | delete | \[compact, delete\] | medium |
| log.index.interval.bytes | 增加一个条目到offset的间隔 | int | 4096 | \[0,...\] | medium |
| log.index.size.max.bytes | offset索引最大的字节数 | int | 10485760 | \[4,...\] | medium |
| log.message.format.version |  | string | 0.10。0-IV1 |  | medium |
| long.message.timestamp.difference.max.ms | broker收到消息的时间戳和日志中指定的时间戳的最大间隔。如果message.timestamp.type=CreateTime，那么一个消息会在时间间隔大于这个值的时候被抛弃。如果message.timestamp.type=LogAppendTime，则这个值被忽略 | long | 9223372036854775807 | \[0,...\] | medium |
| log.message.timestamp.type | 定义message中的时间戳为message生成的时间还是log加载到broker的时间。值必须为'CreateTime'或‘LogAppendTime’ | string | CreateTime | \[CreateTim, LogAppendTime\] | medium |
| log.preallocate | 创建新segment时是否预分配文件。如果你在windows上使用Kafka，这个值要设为true。 | boolean | false |  | medium |
| log.retention.check.interval.ms | log cleaner检查日志是否有需要删除的时间间隔 | long | 300000 | \[1,...\] | medium |
| max.connections.per.ip | 从每个ip地址来的最大的连接数 | int | 2147483647 | \[1,...\] | medium |
| max.connections.per.ip.overrides |  | string | "" |  | medium |
| num.partitions | 每个topic默认的日志分区数 | int | 1 | \[1,...\] | medium |
| principal.builder.class |  |  |  |  | medium |
| producer.purgatory.purge.interval.requests |  |  |  |  | medium |
| replica.fetch.backoff.ms | fetch分区发生错误的休眠时间 | int | 1000 |  | medium |
| reserved.broker.max.id | 能够用于broker.id的最大值 | int | 1000 | \[0,...\] | medium |
| sasl.enable.mechanisms |  |  |  |  | medium |
| sasl.kerberos.kinit.cmd |  |  |  |  | medium |
| sasl.kerberos.min.time.before.relogin |  |  |  |  | medium |
| sasl.kerberos.principal.to.local.rules |  |  |  |  | medium |
| sasl.kerberos.service.name |  |  |  |  | medium |
| sasl.kerberos.ticket.renew.jitter |  |  |  |  | medium |
| sasl.kerberos.ticket.renew.window.factor |  |  |  |  | medium |
| sasl.mechanism.inter.broker.protocol |  |  |  |  | medium |
| security.inter.broker.protocol | broker间通信的安全协议。合法值有：PLAINTET,SSL,SASL\_PLAINTEXT.SASL\_SSL | string | PLAINTEXT |  | medium |
| ssl.cipher.suites |  |  |  |  | medium |
| ssl.client.auth |  |  |  |  | medium |
| ssl.enabled.protocols |  |  |  |  | medium |
| ssl.key.password |  |  |  |  | medium |
| ssl.keymanager.algorithm |  |  |  |  | medium |
| ssl.keystore.location |  |  |  |  | medium |
| ssl.keystore.password |  |  |  |  | medium |
| ssl.keystore.type |  |  |  |  | medium |
| ssl.protocol |  |  |  |  | medium |
| ssl.provider |  |  |  |  | medium |
| ssl.trustmanager.algorithm |  |  |  |  | medium |
| ssl.truststore.location |  |  |  |  | medium |
| ssl.truststore.password |  |  |  |  | medium |
| ssl.truststore.type |  |  |  |  | medium |
| authorizer.class.name |  |  |  |  | low |
| metric.reporters |  |  |  |  | low |
| metrics.num.samples |  |  |  |  | low |
| metrics.sample.window.ms |  |  |  |  | low |
| quota.window.num |  |  |  |  | low |
| quota.windowsize.seconds |  |  |  |  | low |
| ssl.endpoint.identification.algorithm |  |  |  |  | low |
| zookeeper.sync.time.ms |  |  |  |  | low |

关于broker配置的更多细节可以在kafka.server.KafkaConfig这个类中找到。

topic级别的配置都有一个全局缺省的配置和一个可选的特定于topic的配置。如果没有给出特定于具体topic的配置则使用全局默认的。覆盖默认配置可以在创建topic时通过制定一个或多个--config选项来完成。下面的这个例子创建了一个名为_my-topic_的topic，并设置了最大消息大小和flush频率：

```
> bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic my-topic --partitions 1 --replication-factor 1 --config max.message.bytes=64000 --config flush.messages=1
```

对默认值的覆盖也可以使用alter topic命令在topic创建后进行修改或设置。下面的这个命令更新了_my-topc_的最大消息大小配置：

```
> bin/kafka-toopics.sh --zookeeper locaohost:2181 --alter --topic my-topic --config max.message.bytes=128000
```

删除一个覆盖可以这样：

```
> bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic my-topic --delete-config ma.message.bytes
```

下面是topic级别的配置项。相对于topic级别配置项的broker级别的默认配置在Server Default Property列下，在server配置中修改这个默认值可以在没有指定覆盖配置项的情况下修改topics相关的默认值。

| Property | Default | Server Default Property | Description |
| --- | --- | --- | --- |
| cleanup.policy | delete | log.cleanup.policy | 只能是"delete"和"compact"之一。这个字符串指定了对旧的日志segments的处理规则，默认的规则"delete"会在日志segments的retention time或size limit到达之后删除这些日志的segments。"compact"设置会在topic上启用[log compaction](http://kafka.apache.org/documentation.html#compaction) |
| delete.retention.ms | 86400000（24小时） | log.cleaner.delete.retention.ms | 对于[log compacted](http://kafka.apache.org/documentation.html#compaction) topics的过期未压缩日志segments的保留时间。同时这个设置也给出了consumer如果从offset 0开始消费必须完成的时间边界，以保证这些consumer能够得到最后阶段的一个有效的数据快照（否则在完成scan之前带有删除标记的日志就开始被删除） |
| flush.messages | None | log.flush.interval.messages | 这个设置允许指定强制运行一个数据写入到日志的fsync的消息数。例如，如果这个值设置为1，则每条消息都运行一个fsync了如果设置为5则在每收到5条消息后运行一个fsync。一般情况下我们推荐不要设置这个值，并使用复制持久化，让操作系统自动对消息进行持久化效率会更高。 |
| flush.ms | None | log.flush.interval.ms | 指定强制运行一个数据写入日志的fsync的时间间隔。例如，设置为1000则会每秒运行一次fsync。一般情况下我我们推荐不要设置这个值，并使用复制持久化，让操作系统自动对详细进行持久化效率会更高。 |
| index.interval.bytes | 4096 | log.index.interval.bytes | 这个设置用来控制Kafka对offset索引增加一条索引记录的频率。默认配置保证在每4096个字节索引一条消息。更多的索引能够更准确地读到日志中一条消息的位置，但是会使索引变得很大。你可能并不需要修改这个值。 |
| max.message.bytes | 1,000,000 | message.max.bytes | Kafka允许加载到topic的单挑消息的最大字节数。需要注意的是，如果你增加这个值，你必须同时增加consumer的fetch size，这样consumer才能fecth到这么多字节的消息。 |
| min.cleanable.dirty.ratio | 0.5 | log.cleaner.min.cleanable.ratio | 这个配置用来控制log compactor清除日志（假设启用了[log compaction](http://kafka.apache.org/documentation.html#compaction)）的平率。默认情况下大于50%的日志已经被压缩的情况下我们避免清除日志。这个比率限定了浪费的最大磁盘空间，通过删除重复日志实现（最多50%的日志重复需要被删除）。更高的比率意义不大，清除更高效但是会浪费更多磁盘 |
| min.insync.replicas | 1 | min.insync.replicas | 如果一个producer设置acks为"all"，min.insync.replicas指定了必须相应一个写操作成功的replica最小个数。如果没有达到这个最小值，producer会抛异常（NotEnoughReplicas或NotEnoughReplicasAfterAppend）。同时使用min.insync.replicas和acks能够达到更好的持久化保证。一个典型的场景是创建一个topic，副本数为3，min.insync.replicas为2，producer设置acks为"all"，这能够保证在大多数replicas没有响应一个写请求的情况下producer抛异常。 |
| retention.bytes | None | log.retention.bytes | 这个配置指定了删除旧日志segments释放空间之前的最大日志量（如果使用"delete"清除规则）。默认没有大小限制只有时间限制。 |
| retention.ms | 7 Days | log.retention.minutes | 这个配置指定了删除旧日志segments释放空间之前的保留日志的最长时间（如果使用"delete"清除规则）。这代表了一个consumer多快读取数据的SLA。 |
| segments.bytes | 1GB | log.segments.bytes | 这个配置指定了日志的segment文件大小。数据保留（retaintion）和清除（cleaning）总是基于文件的，因此一个大的segment大小意味着更少的文件，但是也意味着更少的retantion粒度控制。 |
| segment.index.bytes | 10MB | log.index.sizemax.bytes | 这个配置指定了映射offsets到message在文件中位置的索引大小。我们会预分配这个索引文件，并且会在log roll后减小这个文件大小。你一般不需要修改这个设置。 |
| segment.ms | 7 days | log.roll.hours | 这个设置指定了在这个时间段后Kafka强制日志roll到新的segment文件，即使老的segment文件没有写满，这用来保证retention能够删除或者压缩旧数据。 |
| segment.jitter.ms | 0 | log.roll.jitter.{ms,hour} | 从logRollTimeMillis中抽离的最大jitter。 |
