# Kafka Streams配置

下面是Kafka Streams客户端的配置。

|Name|Description|Type|Default|Valid Values|Importance|
|-|-|-|-|-|-|
|application.id|流处理程序的唯一id。在Kafka集群中必须唯一。它被用作1）默认的client-id的前缀；2）用于成员管理的group-id；3）changelog topic的前缀|string|||high|
|bootstrap.servers|一个host\/port对列表，用于创建到Kafka cluster的初始连接。客户端会使用所有的Kafka servers，而不只是这个选项中列出的用于初始化立连接的servers。这个列表只是用于发现完整servers集合的初始化主机集合。这个列表的形式为host1:port1,host2:port2,...。由于这些server只是用于初始化连接发现完完整集群（可能会动态变化）的，因此这个列表没必要包含所有的server（你可能想要指定多于一个server，以防server宕机）|lsit|||high|
|client.id|发起请求时传递给server的id字符串。|string|""||high|
|zookeeper.connect|用于Kafka topic管理的Zookeeper连接字符串|string|""||high|
|key.serde|用于实现了Serde接口的key的Serializer/Deserializer类|class|class org.apache.kafka.common.serialization.Serdes$ByteArraySerde||medium|
|partition.grouper|实现了PartitionGrouper接口的Partition grouper类|class|class org.apache.kafka.streams.processor.DefaultPartitionGrouper||medium|
|replication.factor|用于流处理程序创建的changelog topics和repartition topics的副本数|int|1||medium|
|state.dir|用于状态存储的目录|string|/tmp/kafka-streams||medium|
|timestamp.extractor|实现了TimestampExtractor接口的Timestamp extractor类。|class|class org.apache.kafka.streams.processor.ConsumerRecordTimestampExtractor||medium|
|value.serde|实现了Serde接口的用于value的Serializer/Deserializer类|class|class org.apache.kafka.common.serialization.Serdes$ByteArraySerde||medium|
|buffered.records.per.partition|每个分区缓冲的记录数|int|1000||low|
|commit.interval.ms|保存处理器位置的频率|long|30000||low|
|metric.reporters|||||low|
|metrics.num.samples|||||low|
|metrics.sample.window.ms|||||low|
|num.standby.replicas|每个任务standby replicas数|int|0||low|
|num.stream.threads|执行流处理的线程数|int|1||low|
|poll.ms|等待输入阻塞的毫秒数|long|100||low|
|state.cleanup.delay.ms|当一个partition被迁移，在删除状态之前等待的毫秒数。|long|60000||low|


