# 简介
Kafka是一个分布式、数据可分区、可复制的提交日志服务。同时它也具备消息系统的功能，并使用统一的设计架构。

那么这是如何体现的？

首先让我们熟悉一下基本的消息术语：

* Kafka在被称为主题（topics）的分类中维护注入的消息。
* 我们把将消息发布到Kafka主题中的进程称为生产者（producers）。
* 我们把订阅主题并处理发布到主题中的消息的进程称为消费者（consumers）。
* Kafka作为集群运行，由一个或多个被称为中间代理（brokers）的服务组成。

因此，可以这么说，producers通过网络发送消息到Kafka集群，Kafka集群提供服务给consumers，由consumers处理这些消息：

 ![](http://kafka.apache.org/images/producer_consumer.png)

客户端（consumers和producers）和服务端（brokers）之间的通信由一个简单、高性能、语言无关的[TCP协议](https://kafka.apache.org/protocol.html)实现。我们提供了一个Kafa的Java客户端，但是Kafka客户端可以用[很多语言](https://cwiki.apache.org/confluence/display/KAFKA/Clients)实现。

## Toics和Logs
让我们先来了解一下Kafka提供的高级抽象 - topic。

topic是一个分类或者说是供给名称，消息被发布到topic中。对于每个topic来说，Kafka集群维护一个被分区的日志，就像下图：


![](http://kafka.apache.org/images/log_anatomy.png)

每个分区都是一个有序的、不可变的消息序列，这个消息序列被被持续追加消息-一个持续提交日志。分区中的每条消息都被分配一个被称为_offset_的序列号，用来唯一标记分区中的每条消息。

Kafka集群在一个可配置的时间段内保有所有发布的消息，不管它们是否已经被消费。例如，如果消息保持时间呗设为2天，那么在一条消息发布之后的两天内，它都可以用来消费，2天之后它会被移除以节省磁盘空间。Kafka的性能对于数据量来说是常数的，因此它保有大量数据并没有任何问题。

事实上，Kafka维护的基于每个consumer的元数据只有日志中consumer的位置，这个位置被称为"offset"。这个offset由consumer操纵：一般来说一个consumer会随着读取消息而  线性递增offset的值，但是实际上consumer可以以任何它喜欢的顺序去消费消息。例如，一个consumer可以重置旧的offset以达到重新处理消息的目的。

这种特性的融合（保有大量数据、分区机制以及offset系统）意味着Kafka consumers非常易得-它们可以来去自如并且不会对Kafka集群或者其他consumers有太大影响。例如，你可以使用命令行工具去"tail"任何topic中的数据，这并不会改变其他已存在的consumers消费的内容。

日志中的分区机制能服务于多个目标。首先，它们支持脱离单机的日志量扩展。每个独立的分区必须能够被一台主机加载，但是一个topic可能有很多分区，因此它能够处理任意多的数据。其次，分区代表了并行度，这部分在后面会有解释。

## 分布

日志的分区域分布在整个Kafka集群当中，集群中的每台主机负责处理数据，并接受对日志分区的请求。每个分区（中的数据）在一组可配置的主机之间复制，用于容错。

日志的每个分区都存在于一个扮演"leader"角色的主机上，同时在0到多个扮演"followers"的主机上复制。leader处理所有对特定分区的读写请求，followers被动复制leader分片。如果leader失效，followers中的一个会自动成为新的leader。集群中的每台主机会扮演所有分区中部分分片的leader，每台主机会同时扮演其他分区的follower，因此集群的负载被很好地均衡在每台主机上。

## Producers
producers发布数据到所选的topics中。producer负责选择在topic内哪条消息分配给哪个分区。这个是基于轮询（round-robin）的方式实现简单的负载均衡，或者可以依据某个分区函数（可能是基于消息中的某个字段）。稍后会详细介绍分区的用法。

## Consumers
消息系统答题上有两种模型：**消息队列**和**发布订阅**。在队列中，一组consumers可能会从一个服务器读取消息，每条消息会分配给这组consumers的其中之一；在发布订阅模式中，一条消息会广播给所有的consumers。Kafka提供了一个consumer抽象叫做***consumer group***，可以实现这两种模型。

consumers用一个consumer group名称来标记自己，每条发布到topic中的消息会被（broker）转发给每个订阅这个topic的consumer group中的一个consumer实例。consumer实例可以是不同的进程或存在于不同的主机上。

如果所有的consumer实例拥有同一个consumer group名，那么这种模式像是一个传统的消息队列，数据在所有consumer实例之间负载均衡（在consumer group内的模式为消息队列）。

如果所有consumer实例属于不同的consumer group，那么种种模式像是发布订阅系统，所有消息会广播给所有consumers（在consumer group间的模式为发布订阅）。

![](http://kafka.apache.org/images/consumer-groups.png)
#####_两台服务器组成的Kafka集群，其上有4个分区（P0 - P3）以及2个consumer group。consumer group A有两个consumer实例，consumer group B有4个consumer实例。_

我们发现在一般情况下，topics会有较少数量的consumer group，每个consumer group都是一个"逻辑订阅者"。每个group由很多consumer实例组成，用于扩展和容错。这在语义上就是一个发布订阅系统，订阅者是一个consumer集群（consumer group）而不是一个单一进程。

Kafka能够提供绝对的顺序保证，这是传统消息系统做不到的。

一个传统的消息队列能偶保证消息在服务端有序，如果多个consumer从队列中读取消息，则服务端将消息按照它们存储的顺序转发给请求的consumers。然而，尽管server按顺序转发消息，消息还是以异步的方式发送给consumer的，因此它们到达不同consumer的顺序是无序的。这意味着在并发consume的场景中丢失了消息的顺序。消息系统通常会使用一个"专用consumer"的概念，即只允许一个consumer从queue中读取消息，来解决这个无序的问题，但是这当然意味着没有并发处理。

Kafka对于保证有序这件事采用更合理的方式。通过一个并行的概念：在topic中分区，Kafka可以保证消息有序以及在一组consumer进程上的负载均衡。通过将一个topic中的多个分区分配给一个特定consumer group中的所有consumer实例，从而每个分区仅被一group中的一个consumer消费（**_一个分区只能被一个consumer group中的一个consumer消费，一个consumer可以消费多个分区，分区和consumer是多对一的关系_**）。通过这种方式我们可以保证（一个consumer group中的）一个consumer是某个特定分区唯一的消费者，并按顺序消费数据（**_可以看出分区数等于consumer group中的consumer实例数，可以做到一个分区对应一个consumer，达到最优的并发处理和负载均衡，如果consumer数大于分区数，会有consumer闲置_**）。由于会有很多分区，因此始终会在多个consumer实例之间达到负载均衡。需要注意的是，在一个consumer group中不能有超过分区数的consumer实例个数。

Kafka只提供**_分区内的_**消息有序，在topic的不同分区之间不保证有序。对于大多数应用程序来说，每分区有序结合数据分区特性足够满足需求。如果你需要消息全局有序，可以设置一个topic只有一个分区，然后这种方式意味着每个consumer group只能有一个consumer实例。

## 保证
从较高的设计角度来说，Kafka提供以下保证：

* producer发送到一个特定topic分区的消息会按发送它们的顺序追加到分区中。也就是说，如果发送消息M1和M2的producer是同一个，并且M1先发送，则M1会有比M2更低的offset，并且更先出现在日志中。
* 一个consumer实例按照消息存储在日志中的顺序消费它们。
* 对于一个有复制系数N的topic，我们可以做到容忍N-1台服务器失效并且不会丢失任何提交到日志的消息。

对于这些保证的更多细节会在文档的设计部分给出。





