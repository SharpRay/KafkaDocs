# 简介
Kafka是一个分布式、数据可分区、可复制的提交日志服务。同时它也具备消息系统的功能，并使用统一的设计架构。

那么这是如何体现的？

首先让我们熟悉一下基本的消息术语：

* Kafka在被称为主题（topics）的分类中维护注入的消息。
* 我们把将消息发布到Kafka主题中的进程称为生产者（producers）。
* 我们把订阅主题并处理发布到主题中的消息的进程称为消费者（consumers）。
* Kafka作为集群运行，由一个或多个被称为中间代理（brokers）的服务组成。

因此，可以这么说，producers通过网络发送消息到Kafka集群，Kafka集群提供服务给consumers，由consumers处理这些消息：

 ![](http://kafka.apache.org/images/producer_consumer.png)

客户端（consumers和producers）和服务端（brokers）之间的通信由一个简单、高性能、语言无关的[TCP协议](https://kafka.apache.org/protocol.html)实现。我们提供了一个Kafa的Java客户端，但是Kafka客户端可以用[很多语言](https://cwiki.apache.org/confluence/display/KAFKA/Clients)实现。

## Toics和Logs
让我们先来了解一下Kafka提供的高级抽象 - topic。

topic是一个分类或者说是供给名称，消息被发布到topic中。对于每个topic来说，Kafka集群维护一个被分区的日志，就像下图：


![](http://kafka.apache.org/images/log_anatomy.png)

每个分区都是一个有序的、不可变的消息序列，这个消息序列被被持续追加消息-一个持续提交日志。分区中的每条消息都被分配一个被称为_offset_的序列号，用来唯一标记分区中的每条消息。

Kafka集群在一个可配置的时间段内保有所有发布的消息，不管它们是否已经被消费。例如，如果消息保持时间呗设为2天，那么在一条消息发布之后的两天内，它都可以用来消费，2天之后它会被移除以节省磁盘空间。Kafka的性能对于数据量来说是常数的，因此它保有大量数据并没有任何问题。

事实上，Kafka维护的基于每个consumer的元数据只有日志中consumer的位置，这个位置被称为"offset"。这个offset由consumer操纵：一般来说一个consumer会随着读取消息而线性递增offset的值，但是实际上consumer可以以任何它喜欢的顺序去消费消息。例如，一个consumer可以重置旧的offset以达到重新处理消息的目的。

这种特性的融合（保有大量数据、分区机制以及offset系统）意味着Kafka consumers非常易得-它们可以来去自如并且不会对Kafka集群或者其他consumers有太大影响。例如，你可以使用命令行工具去"tail"任何topic中的数据，这并不会改变其他已存在的consumers消费的内容。

日志中的分区机制能服务于多个目标。首先，它们支持脱离单机的日志量扩展。每个独立的分区必须能够被一台主机加载，但是一个topic可能有很多分区，因此它能够处理任意多的数据。其次，分区代表了并行度，这部分在后面会有解释。

## 分布式


